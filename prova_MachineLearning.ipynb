{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8d79f6b9-df88-40b4-8b67-c05057a08083",
   "metadata": {},
   "source": [
    "<center><b><i>UFPA PPGCC-FACOMP: Aprendizado de Máquina </center>\n",
    "    <br>\n",
    "<center>Lista de Exercício Final - Valor 10 pts – <b>Data de entrega 07/12/2022 – Entrega via SIGAA</b> <br></center>\n",
    "Aluno: <b>Jean Carlos de Carvalho Costa</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c77b513c-3a97-4119-87f5-894eb391e3b0",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Questão 1\n",
    "[2.0 pts] Use os dados <a href=\"https://archive.ics.uci.edu/ml/datasets/breast+cancer+wisconsin+(diagnostic)\">Breast Cancer Wisconsin (Diagnostic) Data Set</a> do UCI Machine Learning Repository. Use validação cruzada para avaliar qual dos algoritmos tem maior acurácia nos dados: <br>\n",
    "• SVM Linear <br>\n",
    "• SVM RBF <br>\n",
    "Decida que tipo de padronização (normalização) dos dados você usará para cada algoritmo (ou nenhuma). justifique."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "434cb53b-9862-4670-8357-11f17a554dbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import cross_val_score, train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "# from sklearn import metrics\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "514c85f5-9aef-48d0-b5e0-b278f12a58d4",
   "metadata": {},
   "source": [
    "> Class\n",
    "> ***\n",
    "\n",
    "|Class|description|\n",
    "|---|---|\n",
    "|2|for benign|\n",
    "|4|for malignant|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "849d8d83-1267-4a31-b431-3f2a0d8f12e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_cancer = pd.read_csv('dados/breast-cancer-wisconsin.csv')\n",
    "wdbc = pd.read_csv('dados/wdbc.csv')\n",
    "wpbc = pd.read_csv('dados/wpbc.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "943950ae-cd08-40ac-8c5f-63da5070f678",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID number</th>\n",
       "      <th>Diagnosis</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>radius_worst</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal dimension_worst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>842302</td>\n",
       "      <td>M</td>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>...</td>\n",
       "      <td>25.38</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>842517</td>\n",
       "      <td>M</td>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>...</td>\n",
       "      <td>24.99</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>84300903</td>\n",
       "      <td>M</td>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>...</td>\n",
       "      <td>23.57</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>84348301</td>\n",
       "      <td>M</td>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>...</td>\n",
       "      <td>14.91</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>84358402</td>\n",
       "      <td>M</td>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>...</td>\n",
       "      <td>22.54</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID number Diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
       "0     842302         M        17.99         10.38          122.80     1001.0   \n",
       "1     842517         M        20.57         17.77          132.90     1326.0   \n",
       "2   84300903         M        19.69         21.25          130.00     1203.0   \n",
       "3   84348301         M        11.42         20.38           77.58      386.1   \n",
       "4   84358402         M        20.29         14.34          135.10     1297.0   \n",
       "\n",
       "   smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
       "0          0.11840           0.27760          0.3001              0.14710   \n",
       "1          0.08474           0.07864          0.0869              0.07017   \n",
       "2          0.10960           0.15990          0.1974              0.12790   \n",
       "3          0.14250           0.28390          0.2414              0.10520   \n",
       "4          0.10030           0.13280          0.1980              0.10430   \n",
       "\n",
       "   ...  radius_worst  texture_worst  perimeter_worst  area_worst  \\\n",
       "0  ...         25.38          17.33           184.60      2019.0   \n",
       "1  ...         24.99          23.41           158.80      1956.0   \n",
       "2  ...         23.57          25.53           152.50      1709.0   \n",
       "3  ...         14.91          26.50            98.87       567.7   \n",
       "4  ...         22.54          16.67           152.20      1575.0   \n",
       "\n",
       "   smoothness_worst  compactness_worst  concavity_worst  concave points_worst  \\\n",
       "0            0.1622             0.6656           0.7119                0.2654   \n",
       "1            0.1238             0.1866           0.2416                0.1860   \n",
       "2            0.1444             0.4245           0.4504                0.2430   \n",
       "3            0.2098             0.8663           0.6869                0.2575   \n",
       "4            0.1374             0.2050           0.4000                0.1625   \n",
       "\n",
       "   symmetry_worst  fractal dimension_worst   \n",
       "0          0.4601                   0.11890  \n",
       "1          0.2750                   0.08902  \n",
       "2          0.3613                   0.08758  \n",
       "3          0.6638                   0.17300  \n",
       "4          0.2364                   0.07678  \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wdbc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d7a13a1d-1a42-41fb-8881-9057785b0a7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = wdbc.drop('Diagnosis',axis=1)\n",
    "Y = wdbc[\"Diagnosis\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c663ef4a-2e99-43e9-a6f8-9b0db6b8daa8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'X' shape: (569, 31)\n",
      "'y' shape: (569,)\n"
     ]
    }
   ],
   "source": [
    "print(f\"'X' shape: {X.shape}\")\n",
    "print(f\"'y' shape: {Y.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "60c408cf-6d4f-4d63-9043-d74ef9da46ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('min_max_scaler', MinMaxScaler()),\n",
    "    ('std_scaler', StandardScaler())\n",
    "])\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.10, random_state=101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6bc7a136-f378-468a-bfe2-80ac54bce585",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_score(clf, X_train, y_train, X_test, y_test, train=True):\n",
    "    if train:\n",
    "        pred = clf.predict(X_train)\n",
    "        clf_report = pd.DataFrame(classification_report(y_train, pred, output_dict=True))\n",
    "        print(\"Train Result:\\n================================================\")\n",
    "        print(f\"Accuracy Score: {accuracy_score(y_train, pred) * 100:.2f}%\")\n",
    "        print(\"_______________________________________________\")\n",
    "        print(f\"CLASSIFICATION REPORT:\\n{clf_report}\")\n",
    "        print(\"_______________________________________________\")\n",
    "        print(f\"Confusion Matrix: \\n {confusion_matrix(y_train, pred)}\\n\")\n",
    "        \n",
    "    elif train==False:\n",
    "        pred = clf.predict(X_test)\n",
    "        clf_report = pd.DataFrame(classification_report(y_test, pred, output_dict=True))\n",
    "        print(\"Test Result:\\n================================================\")        \n",
    "        print(f\"Accuracy Score: {accuracy_score(y_test, pred) * 100:.2f}%\")\n",
    "        print(\"_______________________________________________\")\n",
    "        print(f\"CLASSIFICATION REPORT:\\n{clf_report}\")\n",
    "        print(\"_______________________________________________\")\n",
    "        print(f\"Confusion Matrix: \\n {confusion_matrix(y_test, pred)}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0b030b3-f972-4aff-b3b3-1ede51a6529b",
   "metadata": {},
   "source": [
    "#### SVM Linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b4859248-e453-45ef-a75f-4745b5e4bb84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Result:\n",
      "================================================\n",
      "Accuracy Score: 40.62%\n",
      "_______________________________________________\n",
      "CLASSIFICATION REPORT:\n",
      "                    B           M  accuracy   macro avg  weighted avg\n",
      "precision    0.875000    0.383197   0.40625    0.629098      0.692495\n",
      "recall       0.065217    0.984211   0.40625    0.524714      0.406250\n",
      "f1-score     0.121387    0.551622   0.40625    0.336505      0.281045\n",
      "support    322.000000  190.000000   0.40625  512.000000    512.000000\n",
      "_______________________________________________\n",
      "Confusion Matrix: \n",
      " [[ 21 301]\n",
      " [  3 187]]\n",
      "\n",
      "Test Result:\n",
      "================================================\n",
      "Accuracy Score: 40.35%\n",
      "_______________________________________________\n",
      "CLASSIFICATION REPORT:\n",
      "                   B          M  accuracy  macro avg  weighted avg\n",
      "precision   0.666667   0.388889  0.403509   0.527778      0.559454\n",
      "recall      0.057143   0.954545  0.403509   0.505844      0.403509\n",
      "f1-score    0.105263   0.552632  0.403509   0.328947      0.277932\n",
      "support    35.000000  22.000000  0.403509  57.000000     57.000000\n",
      "_______________________________________________\n",
      "Confusion Matrix: \n",
      " [[ 2 33]\n",
      " [ 1 21]]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jeanc\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "model = LinearSVC(loss='hinge', dual=True)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "print_score(model, X_train, y_train, X_test, y_test, train=True)\n",
    "print_score(model, X_train, y_train, X_test, y_test,train = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "006ccea7-8bb2-47be-9a66-84b2250138eb",
   "metadata": {},
   "source": [
    "#### SVM - RBF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e68fc09e-c9b3-4c6a-8189-fe3e0d3c97c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Result:\n",
      "================================================\n",
      "Accuracy Score: 62.89%\n",
      "_______________________________________________\n",
      "CLASSIFICATION REPORT:\n",
      "                    B      M  accuracy   macro avg  weighted avg\n",
      "precision    0.628906    0.0  0.628906    0.314453      0.395523\n",
      "recall       1.000000    0.0  0.628906    0.500000      0.628906\n",
      "f1-score     0.772182    0.0  0.628906    0.386091      0.485630\n",
      "support    322.000000  190.0  0.628906  512.000000    512.000000\n",
      "_______________________________________________\n",
      "Confusion Matrix: \n",
      " [[322   0]\n",
      " [190   0]]\n",
      "\n",
      "Test Result:\n",
      "================================================\n",
      "Accuracy Score: 61.40%\n",
      "_______________________________________________\n",
      "CLASSIFICATION REPORT:\n",
      "                   B     M  accuracy  macro avg  weighted avg\n",
      "precision   0.614035   0.0  0.614035   0.307018      0.377039\n",
      "recall      1.000000   0.0  0.614035   0.500000      0.614035\n",
      "f1-score    0.760870   0.0  0.614035   0.380435      0.467201\n",
      "support    35.000000  22.0  0.614035  57.000000     57.000000\n",
      "_______________________________________________\n",
      "Confusion Matrix: \n",
      " [[35  0]\n",
      " [22  0]]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jeanc\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\jeanc\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\jeanc\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\jeanc\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\jeanc\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\jeanc\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "model = SVC(kernel='rbf', gamma=0.5, C=0.1)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "print_score(model, X_train, y_train, X_test, y_test, train=True)\n",
    "print_score(model, X_train, y_train, X_test, y_test, train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a10395e2-d749-4a89-97a1-d450a13398b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pipeline.fit_transform(X_train)\n",
    "X_test = pipeline.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "dbb7c277-9c27-4c6d-bc55-75a538e4f569",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 126 candidates, totalling 630 fits\n",
      "Best params: {'C': 0.1, 'gamma': 1, 'kernel': 'linear'}\n",
      "Train Result:\n",
      "================================================\n",
      "Accuracy Score: 98.44%\n",
      "_______________________________________________\n",
      "CLASSIFICATION REPORT:\n",
      "                    B           M  accuracy   macro avg  weighted avg\n",
      "precision    0.981595    0.989247  0.984375    0.985421      0.984435\n",
      "recall       0.993789    0.968421  0.984375    0.981105      0.984375\n",
      "f1-score     0.987654    0.978723  0.984375    0.983189      0.984340\n",
      "support    322.000000  190.000000  0.984375  512.000000    512.000000\n",
      "_______________________________________________\n",
      "Confusion Matrix: \n",
      " [[320   2]\n",
      " [  6 184]]\n",
      "\n",
      "Test Result:\n",
      "================================================\n",
      "Accuracy Score: 100.00%\n",
      "_______________________________________________\n",
      "CLASSIFICATION REPORT:\n",
      "              B     M  accuracy  macro avg  weighted avg\n",
      "precision   1.0   1.0       1.0        1.0           1.0\n",
      "recall      1.0   1.0       1.0        1.0           1.0\n",
      "f1-score    1.0   1.0       1.0        1.0           1.0\n",
      "support    35.0  22.0       1.0       57.0          57.0\n",
      "_______________________________________________\n",
      "Confusion Matrix: \n",
      " [[35  0]\n",
      " [ 0 22]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = {'C': [0.01, 0.1, 0.5, 1, 10, 100], \n",
    "              'gamma': [1, 0.75, 0.5, 0.25, 0.1, 0.01, 0.001], \n",
    "              'kernel': ['rbf', 'poly', 'linear']} \n",
    "\n",
    "grid = GridSearchCV(SVC(), param_grid, refit=True, verbose=1, cv=5)\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "best_params = grid.best_params_\n",
    "print(f\"Best params: {best_params}\")\n",
    "\n",
    "svm_clf = SVC(**best_params)\n",
    "svm_clf.fit(X_train, y_train)\n",
    "print_score(svm_clf, X_train, y_train, X_test, y_test, train=True)\n",
    "print_score(svm_clf, X_train, y_train, X_test, y_test, train=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b440543-8bed-4230-89bd-56cc036480f1",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Questão 2\n",
    "[2.0 pts] Uma loja vende cinco produtos: A, B, C, D e E. O gerente lhe pede para minerar regras de associaçãoa partir do <br> banco de dados de transações descrito abaixo: <br>\n",
    "\n",
    "|ID - Transacao|A|B|C|D|\n",
    "|---|---|---|---|---|\n",
    "|T1|1|1|1|0|0|\n",
    "|T2|1|1|1|1|1| \n",
    "|T3|1|0|1|1|0| \n",
    "|T4|1|0|1|1|1|\n",
    "|T5|1|1|1|1|0|\n",
    "\n",
    "\n",
    "<br>\n",
    "onde Ti é o identificador único da transação. Um “1” em uma coluna indica que o produto correspondente foi comprado na transação. Por exemplo, na T1, foram comprados os itens A, B e C. Use o algoritmo Apriori, com suporte 50% e confiança de 80%. Descreva cada passo do algoritmo e liste as regras finais que devem ser usadas, caso haja alguma."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "049b0ed6-9ffd-4474-9eee-54e7d28c673e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d68acf5b-b17e-470f-b4a9-526ab89bc80a",
   "metadata": {},
   "source": [
    "### Questão 3\n",
    "[2.0 pts] Dado o conjunto de dados abaixo:\n",
    "\n",
    "a) aplique o método de agrupamento aglomerativo utilizando a métrica single-link e o critério de dissimilariade distância Euclidiana.\n",
    "\n",
    "b) aplique o algoritmo K-means utilizando distância Euclidiana considerando K = 3. O Algoritmo deve parar caso não apresente convergência após 5 iterações. Considere também que os centros iniciais são: cliente1 e cliente4.\n",
    "\n",
    "| |X1|X2|X3|X4|X5|\n",
    "|---|---|---|---|---|---|\n",
    "|C_1|7,000|10,000|9,000|7,000|10,000|\n",
    "|C_2|9,000|9,000|8,000|9,000|9,000| \n",
    "|C_3|5,000|5,000|6,000|7,000|7,000| \n",
    "|C_4|6,000|6,000|3,000|3,000|4,000|\n",
    "|C_5|1,000|2,000|2,000|1,000|2,000|\n",
    "|C_6|4,000|3,000|2,000|3,000|3,000|\n",
    "|C_7|2,000|4,000|5,000|2,000|5,000|"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c0b5157-2461-4455-a318-d842362edf60",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Questão 4\n",
    "[2.0 pts] Implemente em uma linguagem de programação de sua escolha uma Rede Neural Artificial Multilayer Perceptron treinada com o algoritmo backpropagation que resolva o problema do <b>OU-EXCLUSIVO</b>. Avalie como ficaria a solução se considerarmos uma arquitetura com 2 neurônios na cada escondida e um neurônio na camada de saída. Lembrando que a função de ativação do neurônio deve ser sigmoide."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "959739bb-1579-4787-8c41-a2d7b84e512b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importação de bibliotecas\n",
    "import numpy as np\n",
    "import random as random\n",
    "\n",
    "#Definição de funções:\n",
    "def sigmoid(sum):\n",
    "    \"\"\"Retorna o resultado da função sigmoid\"\"\"\n",
    "    return 1/(1+np.exp(-sum))\n",
    "\n",
    "def sigmoid_derivative(sigmoid):\n",
    "    \"\"\"Retorna o resultado da derivada da função sigmoid\"\"\"\n",
    "    return sigmoid * (1-sigmoid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f4c436a0-0287-4470-ae2a-3e0ecfab5a8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Inicialização dos pesos de forma randômica\n",
    "def weights_ih(qtd_inputs,qtd_perceptrons):\n",
    "    \"\"\"Esta função inicializa os pesos entre a input layer e a hidden layer\"\"\"\n",
    "    weights0 = 2 * np.random.random([qtd_inputs, qtd_perceptrons]) - 1\n",
    "    return weights0\n",
    "\n",
    "def weights_ho(qtd_outputs,qtd_perceptrons):\n",
    "    \"\"\"Esta função inicializa os pesos entre a hidden layer e a output layer\"\"\"\n",
    "    weights1 = 2 * np.random.random([qtd_perceptrons, qtd_outputs]) - 1\n",
    "    return weights1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f2c652dc-6835-4bb9-b342-5f0b29a0e5c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mlp(inputs,out,weights_0,weights_1,error):\n",
    "    \"\"\"Esta função atualiza os pesos para as camadas: input->hidden(weights_0) e hidden-output (weights_1)\"\"\"\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        \n",
    "        #FeedFoward da Hidden Layer:\n",
    "        #Cálculo da net\n",
    "        net_hidden = np.dot(inputs, weights_0)\n",
    "        #Aplicação da função de ativação no resultado da net\n",
    "        hidden_layer = sigmoid(net_hidden)\n",
    "\n",
    "        #FeedFoward da Output\n",
    "        #Cálculo da net\n",
    "        net_output  = np.dot(hidden_layer, weights_1)\n",
    "        #Aplicação da função de ativação no resultado da net\n",
    "        output_layer = sigmoid(net_output)\n",
    "        \n",
    "        #Implementação do erro\n",
    "        error_output_layer = out - output_layer\n",
    "        \n",
    "        #Print da quantidade de erro x Epoch\n",
    "        average = np.mean(abs(error_output_layer))\n",
    "        if epoch % 10000 == 0:\n",
    "            print('Epoch: ' + str(epoch + 1) + ' Error: ' + str(average))\n",
    "            error.append(average)\n",
    "\n",
    "        #Back Propagation\n",
    "        #Cálculo do delta da camada de saída:\n",
    "        #Derivada do output\n",
    "        derivative_output = sigmoid_derivative(output_layer)\n",
    "        #Cálculo do delta output\n",
    "        delta_output = error_output_layer * derivative_output\n",
    "\n",
    "        #Cálculo do delta da hidden layer\n",
    "        delta_output_x_weight = np.dot(delta_output,weights_1.T)\n",
    "        delta_hidden_layer = delta_output_x_weight * sigmoid_derivative(hidden_layer)\n",
    "\n",
    "        #Atualiação dos erros da output layer\n",
    "        input_x_delta1 = np.dot(hidden_layer.T,delta_output)\n",
    "        weights_1 = weights_1 + (input_x_delta1 * learning_rate)\n",
    "\n",
    "        #Atualiação dos erros da hidden layer\n",
    "        input_x_delta0 = np.dot(inputs.T,delta_hidden_layer)\n",
    "        weights_0 = weights_0 + (input_x_delta0 * learning_rate)\n",
    "    return weights_0,weights_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e3ccf35a-f2dd-4164-bdac-578ea8902c86",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predict\n",
    "def predict(instance,weights0,weights1):\n",
    "    hidden_layer = sigmoid(np.dot(instance,weights0))\n",
    "    output_layer = sigmoid(np.dot(hidden_layer,weights1))\n",
    "\n",
    "    x=[]\n",
    "    for i in output_layer:\n",
    "        x.append(round(i))\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e1e119f6-1363-4b92-a8fa-7388a05a82a0",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'inputs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [46]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#Main Code\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m qtd_inputs \u001b[38;5;241m=\u001b[39m \u001b[43minputs\u001b[49m\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m      3\u001b[0m qtd_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;66;03m#saída binária - somente 01 perceptron na output\u001b[39;00m\n\u001b[0;32m      4\u001b[0m qtd_perceptrons \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'inputs' is not defined"
     ]
    }
   ],
   "source": [
    "#Main Code\n",
    "qtd_inputs = inputs.shape[1]\n",
    "qtd_outputs = 1 #saída binária - somente 01 perceptron na output\n",
    "qtd_perceptrons = 2\n",
    "epochs = 100000\n",
    "learning_rate = 0.01 \n",
    "error = []\n",
    "\n",
    "#Inicialização dos pesos\n",
    "weights_0 = weights_ih(qtd_inputs,qtd_perceptrons)\n",
    "weights_1 = weights_ho(qtd_outputs,qtd_perceptrons)\n",
    "\n",
    "#Atualização dos pesos\n",
    "weights_0,weights_1 = mlp(inputs,out,weights_0,weights_1,error)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa476adc-b030-4991-8722-6cc1a1de1160",
   "metadata": {},
   "source": [
    "### Questão 5\n",
    "[2.0 pts] Implemente o algoritmo K-means. Os parâmetros de entrada são número K de clusters, o número M máximo de iterações, e um arquivo ARFF com o conjunto de treino (assuma que todos os atributos do ARFF devem ser levados em conta). O critério de parada não precisa ser limitado a usar apenas o valor de M. Faça um tratamento (leve em conta) para o caso de algum cluster ficar com nenhum vetor associado à ele."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee952d67-abf4-45f7-a173-524904436dd6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
