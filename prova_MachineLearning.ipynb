{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8d79f6b9-df88-40b4-8b67-c05057a08083",
   "metadata": {},
   "source": [
    "<center><b><i>UFPA PPGCC-FACOMP: Aprendizado de Máquina </center>\n",
    "    <br>\n",
    "<center>Lista de Exercício Final - Valor 10 pts – <b>Data de entrega 07/12/2022 – Entrega via SIGAA</b> <br></center>\n",
    "Aluno: <b>Jean Carlos de Carvalho Costa</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c77b513c-3a97-4119-87f5-894eb391e3b0",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Questão 1\n",
    "[2.0 pts] Use os dados <a href=\"https://archive.ics.uci.edu/ml/datasets/breast+cancer+wisconsin+(diagnostic)\">Breast Cancer Wisconsin (Diagnostic) Data Set</a> do UCI Machine Learning Repository. Use validação cruzada para avaliar qual dos algoritmos tem maior acurácia nos dados: <br>\n",
    "• SVM Linear <br>\n",
    "• SVM RBF <br>\n",
    "Decida que tipo de padronização (normalização) dos dados você usará para cada algoritmo (ou nenhuma). justifique."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "434cb53b-9862-4670-8357-11f17a554dbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import cross_val_score, train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "# from sklearn import metrics\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "514c85f5-9aef-48d0-b5e0-b278f12a58d4",
   "metadata": {},
   "source": [
    "> Class\n",
    "> ***\n",
    "\n",
    "|Class|description|\n",
    "|---|---|\n",
    "|2|for benign|\n",
    "|4|for malignant|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "849d8d83-1267-4a31-b431-3f2a0d8f12e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_cancer = pd.read_csv('dados/breast-cancer-wisconsin.csv')\n",
    "wdbc = pd.read_csv('dados/wdbc.csv')\n",
    "wpbc = pd.read_csv('dados/wpbc.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "943950ae-cd08-40ac-8c5f-63da5070f678",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID number</th>\n",
       "      <th>Diagnosis</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>radius_worst</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal dimension_worst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>842302</td>\n",
       "      <td>M</td>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>...</td>\n",
       "      <td>25.38</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>842517</td>\n",
       "      <td>M</td>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>...</td>\n",
       "      <td>24.99</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>84300903</td>\n",
       "      <td>M</td>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>...</td>\n",
       "      <td>23.57</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>84348301</td>\n",
       "      <td>M</td>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>...</td>\n",
       "      <td>14.91</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>84358402</td>\n",
       "      <td>M</td>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>...</td>\n",
       "      <td>22.54</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID number Diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
       "0     842302         M        17.99         10.38          122.80     1001.0   \n",
       "1     842517         M        20.57         17.77          132.90     1326.0   \n",
       "2   84300903         M        19.69         21.25          130.00     1203.0   \n",
       "3   84348301         M        11.42         20.38           77.58      386.1   \n",
       "4   84358402         M        20.29         14.34          135.10     1297.0   \n",
       "\n",
       "   smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
       "0          0.11840           0.27760          0.3001              0.14710   \n",
       "1          0.08474           0.07864          0.0869              0.07017   \n",
       "2          0.10960           0.15990          0.1974              0.12790   \n",
       "3          0.14250           0.28390          0.2414              0.10520   \n",
       "4          0.10030           0.13280          0.1980              0.10430   \n",
       "\n",
       "   ...  radius_worst  texture_worst  perimeter_worst  area_worst  \\\n",
       "0  ...         25.38          17.33           184.60      2019.0   \n",
       "1  ...         24.99          23.41           158.80      1956.0   \n",
       "2  ...         23.57          25.53           152.50      1709.0   \n",
       "3  ...         14.91          26.50            98.87       567.7   \n",
       "4  ...         22.54          16.67           152.20      1575.0   \n",
       "\n",
       "   smoothness_worst  compactness_worst  concavity_worst  concave points_worst  \\\n",
       "0            0.1622             0.6656           0.7119                0.2654   \n",
       "1            0.1238             0.1866           0.2416                0.1860   \n",
       "2            0.1444             0.4245           0.4504                0.2430   \n",
       "3            0.2098             0.8663           0.6869                0.2575   \n",
       "4            0.1374             0.2050           0.4000                0.1625   \n",
       "\n",
       "   symmetry_worst  fractal dimension_worst   \n",
       "0          0.4601                   0.11890  \n",
       "1          0.2750                   0.08902  \n",
       "2          0.3613                   0.08758  \n",
       "3          0.6638                   0.17300  \n",
       "4          0.2364                   0.07678  \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wdbc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d7a13a1d-1a42-41fb-8881-9057785b0a7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = wdbc.drop('Diagnosis',axis=1)\n",
    "Y = wdbc[\"Diagnosis\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c663ef4a-2e99-43e9-a6f8-9b0db6b8daa8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'X' shape: (569, 31)\n",
      "'y' shape: (569,)\n"
     ]
    }
   ],
   "source": [
    "print(f\"'X' shape: {X.shape}\")\n",
    "print(f\"'y' shape: {Y.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "60c408cf-6d4f-4d63-9043-d74ef9da46ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('min_max_scaler', MinMaxScaler()),\n",
    "    ('std_scaler', StandardScaler())\n",
    "])\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.10, random_state=101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6bc7a136-f378-468a-bfe2-80ac54bce585",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_score(clf, X_train, y_train, X_test, y_test, train=True):\n",
    "    if train:\n",
    "        pred = clf.predict(X_train)\n",
    "        clf_report = pd.DataFrame(classification_report(y_train, pred, output_dict=True))\n",
    "        print(\"Train Result:\\n================================================\")\n",
    "        print(f\"Accuracy Score: {accuracy_score(y_train, pred) * 100:.2f}%\")\n",
    "        print(\"_______________________________________________\")\n",
    "        print(f\"CLASSIFICATION REPORT:\\n{clf_report}\")\n",
    "        print(\"_______________________________________________\")\n",
    "        print(f\"Confusion Matrix: \\n {confusion_matrix(y_train, pred)}\\n\")\n",
    "        \n",
    "    elif train==False:\n",
    "        pred = clf.predict(X_test)\n",
    "        clf_report = pd.DataFrame(classification_report(y_test, pred, output_dict=True))\n",
    "        print(\"Test Result:\\n================================================\")        \n",
    "        print(f\"Accuracy Score: {accuracy_score(y_test, pred) * 100:.2f}%\")\n",
    "        print(\"_______________________________________________\")\n",
    "        print(f\"CLASSIFICATION REPORT:\\n{clf_report}\")\n",
    "        print(\"_______________________________________________\")\n",
    "        print(f\"Confusion Matrix: \\n {confusion_matrix(y_test, pred)}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0b030b3-f972-4aff-b3b3-1ede51a6529b",
   "metadata": {},
   "source": [
    "#### SVM Linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b4859248-e453-45ef-a75f-4745b5e4bb84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Result:\n",
      "================================================\n",
      "Accuracy Score: 64.65%\n",
      "_______________________________________________\n",
      "CLASSIFICATION REPORT:\n",
      "                    B           M  accuracy   macro avg  weighted avg\n",
      "precision    0.640159    1.000000  0.646484    0.820080      0.773694\n",
      "recall       1.000000    0.047368  0.646484    0.523684      0.646484\n",
      "f1-score     0.780606    0.090452  0.646484    0.435529      0.524494\n",
      "support    322.000000  190.000000  0.646484  512.000000    512.000000\n",
      "_______________________________________________\n",
      "Confusion Matrix: \n",
      " [[322   0]\n",
      " [181   9]]\n",
      "\n",
      "Test Result:\n",
      "================================================\n",
      "Accuracy Score: 64.91%\n",
      "_______________________________________________\n",
      "CLASSIFICATION REPORT:\n",
      "                   B          M  accuracy  macro avg  weighted avg\n",
      "precision   0.636364   1.000000  0.649123   0.818182      0.776715\n",
      "recall      1.000000   0.090909  0.649123   0.545455      0.649123\n",
      "f1-score    0.777778   0.166667  0.649123   0.472222      0.541910\n",
      "support    35.000000  22.000000  0.649123  57.000000     57.000000\n",
      "_______________________________________________\n",
      "Confusion Matrix: \n",
      " [[35  0]\n",
      " [20  2]]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jeanc\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\svm\\_base.py:1225: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "model = LinearSVC(loss='hinge', dual=True)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "print_score(model, X_train, y_train, X_test, y_test, train=True)\n",
    "print_score(model, X_train, y_train, X_test, y_test,train = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "006ccea7-8bb2-47be-9a66-84b2250138eb",
   "metadata": {},
   "source": [
    "#### SVM - RBF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e68fc09e-c9b3-4c6a-8189-fe3e0d3c97c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Result:\n",
      "================================================\n",
      "Accuracy Score: 62.89%\n",
      "_______________________________________________\n",
      "CLASSIFICATION REPORT:\n",
      "                    B      M  accuracy   macro avg  weighted avg\n",
      "precision    0.628906    0.0  0.628906    0.314453      0.395523\n",
      "recall       1.000000    0.0  0.628906    0.500000      0.628906\n",
      "f1-score     0.772182    0.0  0.628906    0.386091      0.485630\n",
      "support    322.000000  190.0  0.628906  512.000000    512.000000\n",
      "_______________________________________________\n",
      "Confusion Matrix: \n",
      " [[322   0]\n",
      " [190   0]]\n",
      "\n",
      "Test Result:\n",
      "================================================\n",
      "Accuracy Score: 61.40%\n",
      "_______________________________________________\n",
      "CLASSIFICATION REPORT:\n",
      "                   B     M  accuracy  macro avg  weighted avg\n",
      "precision   0.614035   0.0  0.614035   0.307018      0.377039\n",
      "recall      1.000000   0.0  0.614035   0.500000      0.614035\n",
      "f1-score    0.760870   0.0  0.614035   0.380435      0.467201\n",
      "support    35.000000  22.0  0.614035  57.000000     57.000000\n",
      "_______________________________________________\n",
      "Confusion Matrix: \n",
      " [[35  0]\n",
      " [22  0]]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jeanc\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\jeanc\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\jeanc\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\jeanc\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\jeanc\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\jeanc\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "model = SVC(kernel='rbf', gamma=0.5, C=0.1)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "print_score(model, X_train, y_train, X_test, y_test, train=True)\n",
    "print_score(model, X_train, y_train, X_test, y_test, train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a10395e2-d749-4a89-97a1-d450a13398b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pipeline.fit_transform(X_train)\n",
    "X_test = pipeline.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "dbb7c277-9c27-4c6d-bc55-75a538e4f569",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 126 candidates, totalling 630 fits\n",
      "Best params: {'C': 0.1, 'gamma': 1, 'kernel': 'linear'}\n",
      "Train Result:\n",
      "================================================\n",
      "Accuracy Score: 98.44%\n",
      "_______________________________________________\n",
      "CLASSIFICATION REPORT:\n",
      "                    B           M  accuracy   macro avg  weighted avg\n",
      "precision    0.981595    0.989247  0.984375    0.985421      0.984435\n",
      "recall       0.993789    0.968421  0.984375    0.981105      0.984375\n",
      "f1-score     0.987654    0.978723  0.984375    0.983189      0.984340\n",
      "support    322.000000  190.000000  0.984375  512.000000    512.000000\n",
      "_______________________________________________\n",
      "Confusion Matrix: \n",
      " [[320   2]\n",
      " [  6 184]]\n",
      "\n",
      "Test Result:\n",
      "================================================\n",
      "Accuracy Score: 100.00%\n",
      "_______________________________________________\n",
      "CLASSIFICATION REPORT:\n",
      "              B     M  accuracy  macro avg  weighted avg\n",
      "precision   1.0   1.0       1.0        1.0           1.0\n",
      "recall      1.0   1.0       1.0        1.0           1.0\n",
      "f1-score    1.0   1.0       1.0        1.0           1.0\n",
      "support    35.0  22.0       1.0       57.0          57.0\n",
      "_______________________________________________\n",
      "Confusion Matrix: \n",
      " [[35  0]\n",
      " [ 0 22]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = {'C': [0.01, 0.1, 0.5, 1, 10, 100], \n",
    "              'gamma': [1, 0.75, 0.5, 0.25, 0.1, 0.01, 0.001], \n",
    "              'kernel': ['rbf', 'poly', 'linear']} \n",
    "\n",
    "grid = GridSearchCV(SVC(), param_grid, refit=True, verbose=1, cv=5)\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "best_params = grid.best_params_\n",
    "print(f\"Best params: {best_params}\")\n",
    "\n",
    "svm_clf = SVC(**best_params)\n",
    "svm_clf.fit(X_train, y_train)\n",
    "print_score(svm_clf, X_train, y_train, X_test, y_test, train=True)\n",
    "print_score(svm_clf, X_train, y_train, X_test, y_test, train=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b440543-8bed-4230-89bd-56cc036480f1",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Questão 2\n",
    "[2.0 pts] Uma loja vende cinco produtos: A, B, C, D e E. O gerente lhe pede para minerar regras de associaçãoa partir do <br> banco de dados de transações descrito abaixo: <br>\n",
    "\n",
    "|ID - Transacao|A|B|C|D|E\n",
    "|---|---|---|---|---|---|\n",
    "|T1|1|1|1|0|0|0|\n",
    "|T2|1|1|1|1|1|1|\n",
    "|T3|1|0|1|1|0|0|\n",
    "|T4|1|0|1|1|1|1|\n",
    "|T5|1|1|1|1|0|0|\n",
    "\n",
    "\n",
    "<br>\n",
    "onde Ti é o identificador único da transação. Um “1” em uma coluna indica que o produto correspondente foi comprado na transação. Por exemplo, na T1, foram comprados os itens A, B e C. Use o algoritmo Apriori, com suporte 50% e confiança de 80%. Descreva cada passo do algoritmo e liste as regras finais que devem ser usadas, caso haja alguma."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "049b0ed6-9ffd-4474-9eee-54e7d28c673e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d68acf5b-b17e-470f-b4a9-526ab89bc80a",
   "metadata": {},
   "source": [
    "### Questão 3\n",
    "[2.0 pts] Dado o conjunto de dados abaixo:\n",
    "\n",
    "a) aplique o método de agrupamento aglomerativo utilizando a métrica single-link e o critério de dissimilariade distância Euclidiana.\n",
    "\n",
    "b) aplique o algoritmo K-means utilizando distância Euclidiana considerando K = 3. O Algoritmo deve parar caso não apresente convergência após 5 iterações. Considere também que os centros iniciais são: cliente1 e cliente4.\n",
    "\n",
    "| |X1|X2|X3|X4|X5|\n",
    "|---|---|---|---|---|---|\n",
    "|C_1|7,000|10,000|9,000|7,000|10,000|\n",
    "|C_2|9,000|9,000|8,000|9,000|9,000| \n",
    "|C_3|5,000|5,000|6,000|7,000|7,000| \n",
    "|C_4|6,000|6,000|3,000|3,000|4,000|\n",
    "|C_5|1,000|2,000|2,000|1,000|2,000|\n",
    "|C_6|4,000|3,000|2,000|3,000|3,000|\n",
    "|C_7|2,000|4,000|5,000|2,000|5,000|"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c0b5157-2461-4455-a318-d842362edf60",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Questão 4\n",
    "[2.0 pts] Implemente em uma linguagem de programação de sua escolha uma Rede Neural Artificial Multilayer Perceptron treinada com o algoritmo backpropagation que resolva o problema do <b>OU-EXCLUSIVO</b>. Avalie como ficaria a solução se considerarmos uma arquitetura com 2 neurônios na cada escondida e um neurônio na camada de saída. Lembrando que a função de ativação do neurônio deve ser sigmoide."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d719af6-9864-45fd-ab31-0e9ffcade5dd",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### Algoritmos 1 - Rede Neural"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "1b20168f-5c6c-408a-9f25-01fea7e23887",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Erro:0.5007790033065198\n",
      "Erro:0.5007276234813215\n",
      "Erro:0.5006807843789174\n",
      "Erro:0.5006381334206432\n",
      "Erro:0.5005993254347171\n",
      "Erro:0.5005640283302715\n",
      "Erro:0.5005319270953845\n",
      "Erro:0.5005027263723935\n",
      "Erro:0.5004761518722683\n",
      "Erro:0.5004519508770422\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def sigmoid(soma):\n",
    "    return 1/(1+np.exp(-soma))\n",
    "\n",
    "def sigmoidDerivada(sig):\n",
    "    return sig * (1 - sig)\n",
    "\n",
    "a = sigmoid(0.5)\n",
    "b = sigmoidDerivada(a)\n",
    "\n",
    "entradas = np.array([[0,0],[0,1],[1,0],[1,1]])\n",
    "saidas = np.array([[0],[1],[1],[0]])\n",
    "\n",
    "pesos0 = 2*np.random.random((2,3)) -1\n",
    "pesos1 = 2*np.random.random((3,1)) -1\n",
    "\n",
    "epocas = 10\n",
    "taxaAprendizagem = 0.3\n",
    "momento = 1\n",
    "\n",
    "for i in range(epocas):\n",
    "    camadaEntrada = entradas\n",
    "    somaSinapse0 = np.dot(camadaEntrada, pesos0)\n",
    "    camadaOculta = sigmoid(somaSinapse0)\n",
    "    \n",
    "    somaSinapse1 = np.dot(camadaOculta, pesos1)\n",
    "    camadaSaida = sigmoid(somaSinapse1)\n",
    "    \n",
    "    erroCamadaSaida = saidas - camadaSaida\n",
    "    mediaAbsoluta = np.mean(np.abs(erroCamadaSaida))\n",
    "    print(\"Erro:\" + str(mediaAbsoluta))\n",
    "    \n",
    "    derivadaSaida = sigmoidDerivada(camadaSaida)\n",
    "    deltaSaida = erroCamadaSaida * derivadaSaida\n",
    "    \n",
    "    pesos1Transposta = pesos1.T\n",
    "    deltaSaidaXPeso = deltaSaida.dot(pesos1Transposta)\n",
    "    deltacamadaOculta = deltaSaidaXPeso * sigmoidDerivada(camadaOculta)\n",
    "    \n",
    "    camadaOcultaTransposta = camadaOculta.T\n",
    "    pesosNovo1 = camadaOcultaTransposta.dot(deltaSaida)\n",
    "    pesos1 = (pesos1*momento)+(pesosNovo1*taxaAprendizagem)\n",
    "    \n",
    "    camadaEntradaTransposta = camadaEntrada.T\n",
    "    pesosNovo0 = camadaEntradaTransposta.dot(deltacamadaOculta)\n",
    "    pesos0 = (pesos0*momento)+(pesosNovo0*taxaAprendizagem)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa476adc-b030-4991-8722-6cc1a1de1160",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Questão 5\n",
    "[2.0 pts] Implemente o algoritmo K-means. Os parâmetros de entrada são número K de clusters, o número M máximo de iterações, e um arquivo ARFF com o conjunto de treino (assuma que todos os atributos do ARFF devem ser levados em conta). O critério de parada não precisa ser limitado a usar apenas o valor de M. Faça um tratamento (leve em conta) para o caso de algum cluster ficar com nenhum vetor associado à ele."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "976eb8c5-3381-49d0-9f0f-4216a43ccad3",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Algoritmo 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f1a623f-139b-419e-84de-960756c14922",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Primeiro importamos o modulo.\n",
    "from sklearn.datasets import load_iris\n",
    " \n",
    "#Aqui eu instancio o objeto.\n",
    "iris = load_iris()\n",
    "data = iris.data #Armazeno os dados para treino.\n",
    "labels = iris.target #Aqui são os Labels\n",
    "labels_names = iris.target_names # E aqui o nome de cada Label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee952d67-abf4-45f7-a173-524904436dd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Primeiro definimos a função para calculo de distância.\n",
    "from math import sqrt\n",
    " \n",
    "def euclidian(v1,v2):\n",
    "    \"\"\"Essa função recebe duas\n",
    "       listas e retorna a\n",
    "       distancia entre elas\"\"\"\n",
    " \n",
    "    #Armazena o quadrado da distância\n",
    "    dist = 0.0\n",
    "    for x in range(len(v1)):\n",
    "        dist += pow((v1[x] - v2[x]),2)\n",
    " \n",
    "    #Tira a raiz quadrada da soma\n",
    "    eucli = sqrt(dist)\n",
    "    return eucli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d450d6e5-b514-4da9-9e42-f35611b606ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Precisamos do modulo random\n",
    "import random\n",
    " \n",
    "def Kcluster(data,distance=euclidian,k=4):\n",
    "     \n",
    "    #Determina o valor máximo e mínimo para cada atributo\n",
    "    #Cria uma lista de tuplas que contem valores máximos e mínimos de cada atributo\n",
    "    ranges = [(min([row[i] for row in data]),\n",
    "               max([row[i] for row in data]))\n",
    "               for i in range(len(data[0]))]\n",
    "    \n",
    "    #Cria K centroides aleatórias\n",
    "    #Cria uma lista contendo os K centroides em posições aleatorias.\n",
    "    #No nosso caso serão 3\n",
    "    clusters=[[random.random()*(ranges[i][1] - ranges[i][0])+ranges[i][0]\n",
    "               for i in range(len(data[0]))] for j in range(k)]\n",
    "     \n",
    "    lastmatches = None\n",
    "    #O número de iterações será no máximo 100\n",
    "    for t in range(100):\n",
    "        bestmatches = [[] for i in range(k)]\n",
    "     \n",
    "        #Verifica qual centroide esta mais perto de cada instancia\n",
    "        for j in range(len(data)):\n",
    "            row=data[j]\n",
    "            bestmatche = 0 #Aqui armazeno o índice da menor distância para comparação\n",
    "            for i in range(k):\n",
    "                d = distance(clusters[i],row) #Calcula a distancia em relação ao centroide\n",
    "                if d < distance(clusters[bestmatche],row):\n",
    "                    bestmatche = i\n",
    "            bestmatches[bestmatche].append(j)\n",
    "        #Se o resultado for o mesmo que da ultima vez esta completo\n",
    "        if bestmatches == lastmatches:\n",
    "            break\n",
    "        lastmatches=bestmatche\n",
    "     \n",
    "        #Move o centroide para a zona média do cluster\n",
    "        #no caso teremos \n",
    "        for i in range(k):\n",
    "            avgs=[0.0]*len(data[0])\n",
    "            if len(bestmatches[i])>0:\n",
    "                for rowid in bestmatches[i]:\n",
    "                    for m in range(len(data[rowid])):\n",
    "                        avgs[m] += data[rowid][m]\n",
    "                for j in range(len(avgs)):\n",
    "                    avgs[j] /= len(bestmatches[i])\n",
    "                clusters[i]=avgs\n",
    "    \n",
    "    return bestmatches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cabea2ae-32b4-4aa0-a02f-d1ff7339d566",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Aqui retorna um lista de duas dimensões com os índices de cada cluster\n",
    "cluster = Kcluster(data,k=3)\n",
    "#seleciono as instâncias no dataset original de acordo com os seus índices\n",
    "c1 = data[[cluster[0]]]\n",
    "c2 = data[[cluster[1]]]\n",
    "c3 = data[[cluster[2]]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b1624ae-a2d2-4076-b8dc-c8686b7fdbf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    " \n",
    "#a liste de valores que serão plotados\n",
    "plots = [c1,c2,c3]\n",
    " \n",
    "fig = plt.figure(236)\n",
    "x = 0\n",
    "y = 1\n",
    " \n",
    "#Os títulos de cada gráfico\n",
    "titles = ['sepal length x sepal width','sepal length x petal length',\n",
    "          'sepal length x petal width','sepal width x petal length',\n",
    "          'sepal width x petal width','petal length x petal width']\n",
    " \n",
    "#Aqui trato de gerar todos os gráficos.\n",
    "for h in range(1,7):\n",
    "    fig.add_subplot(2,3,h)\n",
    "    for plot,color in zip(plots,['r','b','g']):\n",
    "        plt.scatter(plot[:,x],plot[:,y],c=color, alpha=0.7)\n",
    "    if y == 3:\n",
    "        x += 1\n",
    "        y = x + 1\n",
    "    plt.title(titles[h - 1])\n",
    "    plt.xticks(())\n",
    "    plt.yticks(())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f52f1515-5164-4bed-8dab-18eace838fd3",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Algoritmos 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "f7b33270-e5f7-4f64-aedc-e96cbd007c85",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.io.arff import loadarff\n",
    "dataset = loadarff(open('iris.arff','r'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eff7726a-5df6-47df-ad2e-70ebaca1399d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from numpy import *\n",
    "from numpy.random import rand, randint, seed\n",
    "from numpy.linalg import norm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cc11c1b-28ec-4f08-a2a8-a7ddbdfdca5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed(999)\n",
    "n = 2    # dimensão dos vetores\n",
    "m = 9000   # número de entradas\n",
    "k = 3    # número de grupos\n",
    "\n",
    "# Criando um X sintético\n",
    "max_dist_origem = 100\n",
    "max_raio = 10\n",
    "mk = int(floor(m/k)) # vou fazer cada grupo ter m/k vetores\n",
    "\n",
    "centros = max_dist_origem * rand(n,k)\n",
    "raios = max_raio * rand(k)\n",
    "X = random.randn(m, n)\n",
    "\n",
    "for i in range(k):\n",
    "    X[i*mk : (i+1)*mk, :] = X[i*mk : (i+1)*mk, :]*raios[i] + centros[:,i].reshape((1,n))\n",
    "    \n",
    "aa=plt.grid();\n",
    "aa=plt.axis('equal');\n",
    "for i in range(m):\n",
    "    aa=plt.plot(X[i,0],X[i,1],'bo');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef0df6d5-a588-49f6-80dc-27a91683dcf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcula_Z_aleatorio(X, k):\n",
    "\n",
    "    Z = []\n",
    "    Z_i = []\n",
    "\n",
    "    while len(Z_i) != k:\n",
    "\n",
    "        r = randint(0, len(X))\n",
    "\n",
    "        if r not in Z_i:\n",
    "            Z_i.append(r)\n",
    "    \n",
    "    for i in arange(k):\n",
    "        Z.append(X[Z_i[i]])\n",
    "        \n",
    "    return Z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27f1492e-b7c0-41d2-9855-a1d4ea78cd2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.linalg import norm\n",
    "from numpy import argmin\n",
    "\n",
    "def calcula_C_dado_Z(Z, X, k, m):\n",
    "    \n",
    "    C = zeros(len(X))\n",
    "    for j in range(len(X)):\n",
    "        distancias_xj_zi = []\n",
    "        for i in range(k):\n",
    "            distancias_xj_zi.append(norm(X[j] - Z[i]))\n",
    "        C[j] = argmin(distancias_xj_zi)\n",
    "\n",
    "    return C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d537d80-df18-44d4-9698-f3c99901c2b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcula_Z_dado_C(C, X, k, m):\n",
    "    \n",
    "    Z = []\n",
    "    for i in range(k):\n",
    "        \n",
    "        cont = 0\n",
    "        \n",
    "        zi = zeros([k, len(X[0])])\n",
    "        for j in range(m):\n",
    "            if C[j] == i:\n",
    "                zi[i] += X[j]\n",
    "                cont += 1\n",
    "\n",
    "        zi[i] = array(zi[i])\n",
    "        Z.append(zi[i] / cont)\n",
    "        \n",
    "    return Z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90a5e6b2-0757-4683-95d7-8dc9fd18588e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plota_pontos_k_means(m, C, Z):\n",
    "    \n",
    "    aa=plt.grid();\n",
    "    aa=plt.axis('equal');\n",
    "    for i in range(m):\n",
    "        if C[i] == 0:\n",
    "            aa=plt.plot(X[i,0],X[i,1],'go');\n",
    "        elif C[i] == 1:\n",
    "            aa=plt.plot(X[i,0],X[i,1],'ro');\n",
    "        elif C[i] == 2:\n",
    "            aa=plt.plot(X[i,0],X[i,1],'yo');\n",
    "        \n",
    "    for i in range(len(Z)):\n",
    "        aa = plt.plot(Z[i][0], Z[i][1], 'bo')\n",
    "\n",
    "    return aa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d521e1e-1ec7-4ee3-9a78-74a6781a505d",
   "metadata": {},
   "outputs": [],
   "source": [
    "Z0 = calcula_Z_aleatorio(X, k)\n",
    "C0 = calcula_C_dado_Z(Z0, X, k, m)\n",
    "c = 1\n",
    "while(True):\n",
    "    print(f'{c} iteracao')\n",
    "    c += 1\n",
    "    Z = calcula_Z_dado_C(C0, X, k, m)\n",
    "    C = calcula_C_dado_Z(Z, X, k, m)\n",
    "    if all(C == C0):\n",
    "        break\n",
    "    C0 = C\n",
    "        \n",
    "plota_pontos_k_means(m, C, Z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69da659a-9fd8-410d-89cc-110a7b2c1c35",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Vetor classificador de cada um dos pontos de X: \\n', C)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
